{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fda7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4 \n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urlencode, parse_qsl, urlparse, urlunparse\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c6b217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"https://nces.ed.gov/ccd/schoolsearch/\")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "href = \"school_detail.asp?Search=1&InstName=ALDEN+INTERMEDIATE+SCHOOL&State=36&County=Erie&SchoolType=1&SchoolType=2&SchoolType=3&SchoolType=4&SpecificSchlTypes=all&IncGrade=-1&LoGrade=-1&HiGrade=-1&ID=360255006572\"\n",
    "base_url = \"https://nces.ed.gov/ccd/schoolsearch/school_list.asp\"\n",
    "detail_url = base_url + href  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef545bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_response = requests.get(detail_url)\n",
    "detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d04881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_detail_url(school_name, county, address=''):\n",
    "    def try_search(name, addr=''):\n",
    "        base_url = \"https://nces.ed.gov/ccd/schoolsearch/school_list.asp\"\n",
    "        \n",
    "        params = {\n",
    "            \"Search\": \"1\",\n",
    "            \"InstName\": name,\n",
    "            \"Address\": addr,\n",
    "            \"State\": \"36\",        # New York \n",
    "            \"County\": county,\n",
    "            \"SchoolType\": [\"1\", \"2\", \"3\", \"4\"],  \n",
    "            \"SpecificSchlTypes\": \"all\",\n",
    "            \"IncGrade\": \"-1\",\n",
    "            \"LoGrade\": \"-1\",\n",
    "            \"HiGrade\": \"-1\"\n",
    "        }\n",
    "\n",
    "        session = requests.Session()\n",
    "        req = requests.Request('GET', base_url, params=params)\n",
    "        prepped = session.prepare_request(req)\n",
    "\n",
    "        url_parts = list(urlparse(prepped.url))\n",
    "        query = dict(parse_qsl(url_parts[4]))\n",
    "        query.pop('SchoolType', None)\n",
    "        school_types = [\"1\", \"2\", \"3\", \"4\"]\n",
    "        new_query_items = [(k, v) for k, v in query.items()]\n",
    "        for st in school_types:\n",
    "            new_query_items.append((\"SchoolType\", st))\n",
    "        url_parts[4] = urlencode(new_query_items)\n",
    "        final_url = urlunparse(url_parts)\n",
    "\n",
    "        response = session.get(final_url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        link_tag = soup.find('a', href=lambda x: x and \"school_detail.asp\" in x)\n",
    "        if link_tag:\n",
    "            return \"https://nces.ed.gov/ccd/schoolsearch/\" + link_tag['href']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # full name \n",
    "    detail_url = try_search(school_name)\n",
    "    if detail_url:\n",
    "        return detail_url\n",
    "\n",
    "    # first two words if different from full name\n",
    "    first_two_words = ' '.join(school_name.split()[:2])\n",
    "    if len(first_two_words) > 2 and first_two_words != school_name:\n",
    "        detail_url = try_search(first_two_words)\n",
    "        if detail_url:\n",
    "            return detail_url\n",
    "\n",
    "    # first word plus address\n",
    "    first_word = school_name.split()[0]\n",
    "    if address and first_word.lower() != school_name.lower():\n",
    "        detail_url = try_search(first_word, address)\n",
    "        if detail_url:\n",
    "            return detail_url\n",
    "    \n",
    "    # address only, no name\n",
    "    if address:\n",
    "        detail_url = try_search('',address)\n",
    "        if detail_url:\n",
    "            return detail_url\n",
    "        \n",
    "    # first word only\n",
    "    if first_word.lower() != school_name.lower():\n",
    "        detail_url = try_search(first_word)\n",
    "        if detail_url:\n",
    "            return detail_url\n",
    "        \n",
    "    # second word plus address\n",
    "    '''\n",
    "    second_word = school_name.split()[1]\n",
    "    if address and second_word.lower() != school_name.lower():\n",
    "        detail_url = try_search(second_word, address)\n",
    "        if detail_url:\n",
    "            return detail_url\n",
    "    '''        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print(f\"No detail link found for {school_name} in {county}\")\n",
    "    print(f\"Address of school : {address}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83257bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_free_reduced_lunch_total(html):\n",
    "    \"\"\"\n",
    "    Number for 'Free and reduced-price lunch eligible total' from the school detail page HTML.\n",
    "\n",
    "    Parameters:\n",
    "        html (str): HTML content of the school detail page.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The number as a string if found, otherwise None.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    label_part = \"Free and reduced-price lunch eligible total\"\n",
    "\n",
    "    for b in soup.find_all('b'):\n",
    "        if label_part in b.get_text():\n",
    "            value = b.next_sibling\n",
    "            if value:\n",
    "                return value.strip()\n",
    "    return None\n",
    "\n",
    "def get_total_count(html):\n",
    "    \"\"\"\n",
    "    Number for 'Total Students' from the school detail page HTML.\n",
    "\n",
    "    Parameters:\n",
    "        html (str): HTML content of the school detail page.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The number as a string if found, otherwise None.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    label_part = \"Total Students\"\n",
    "\n",
    "    for b in soup.find_all('b'):\n",
    "        if label_part in b.get_text():\n",
    "            value = b.next_sibling\n",
    "            if value:\n",
    "                return value.strip()\n",
    "    return None\n",
    "\n",
    "def get_demographics(html):\n",
    "    \n",
    "    soup    = BeautifulSoup(html,'html.parser')\n",
    "    label   = soup.find('strong', string=\"Enrollment by Race/Ethnicity:\")\n",
    "    table   = label.find_next(\"table\")\n",
    "    rows    = table.find_all(\"tr\")\n",
    "    headers = rows[0].find_all('td')[1:]\n",
    "    ethnicities = [''.join(header.stripped_strings) for header in headers]\n",
    "\n",
    "    num_cells  = rows[1].find_all('td')[1:]\n",
    "    demographics = {}\n",
    "    for header, cell in zip(ethnicities, num_cells):\n",
    "        text = cell.get_text(strip=True).replace(',','')\n",
    "        try:\n",
    "            count = int(text)\n",
    "            demographics[header] = count\n",
    "        except ValueError:\n",
    "            print(f\"Skipped invalid demographic count: '{text}' for ethnicity '{header}'\")\n",
    "            continue\n",
    "    return demographics\n",
    "\n",
    "\n",
    "def get_stud_teacher_ratio(html):\n",
    "\n",
    "    soup= BeautifulSoup(html,'html.parser')\n",
    "    label_parts = \"Student/Teacher Ratio:\"\n",
    "\n",
    "    for b in soup.find_all('b'):\n",
    "        if label_parts in b.get_text():\n",
    "            value = b.next_sibling\n",
    "            print(value)\n",
    "            if value:\n",
    "                return value.strip()\n",
    "    return None\n",
    "\n",
    "def school_name(name):\n",
    "    # Remove parentheses content and 'Dr.' prefix\n",
    "    name = re.sub(r'\\s*\\(.*?\\)\\s*', '', name)\n",
    "    name = re.sub(r'^\\s*Dr\\.?\\s+', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    abbreviation_map = {\n",
    "        'JF': 'John F',\n",
    "        'MLK': 'Martin Luther King',\n",
    "        'RFK': 'Robert F Kennedy',\n",
    "    }\n",
    "\n",
    "    # Replace abbreviation only if name starts with abbreviation\n",
    "    for abbr, full in abbreviation_map.items():\n",
    "        if name.upper().startswith(abbr + ' '):\n",
    "            name = re.sub(r'^' + abbr + r'\\b', full, name, flags=re.IGNORECASE)\n",
    "            break\n",
    "    \n",
    "    name =name.replace('-','')\n",
    "    # Remove single letters that are surrounded by spaces only (not initials)\n",
    "    name = re.sub(r'(?<=\\s)[A-Za-z](?=\\s)', '', name)\n",
    "    # Collapse multiple spaces to one and strip\n",
    "    name = re.sub(r'\\s{2,}', ' ', name).strip()\n",
    "\n",
    "    # Remove suffixes that can interfere\n",
    "    suffix_list = [r'\\bPREK\\b', r'\\bH S\\b', r'\\bES-JS-HS\\b']\n",
    "    for suffix in suffix_list:\n",
    "        name = re.sub(suffix, '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    parts = name.split(',', 1)\n",
    "    main_name = parts[0].strip()\n",
    "    extra_info = parts[1].strip() if len(parts) > 1 else ''\n",
    "\n",
    "    ps_match = re.match(r'PS\\s*(\\d+)', main_name, re.IGNORECASE)\n",
    "    ps_number = int(ps_match.group(1)) if ps_match else None\n",
    "\n",
    "    if ps_match:\n",
    "        main_name = main_name[ps_match.end():].strip()\n",
    "\n",
    "    school_type = ''\n",
    "    suffix_map = {\n",
    "        r'\\bPREK\\b': 'Pre-Kindergarten',\n",
    "        r'\\bES\\b': 'Elementary School',\n",
    "        r'\\bHS\\b': 'High School',\n",
    "        r'\\bMS\\b': 'Middle School',\n",
    "        r'\\bJHS\\b': 'Junior High School',\n",
    "        r'\\bK-12\\b': 'K-12 School',\n",
    "        r'\\bELEM\\b': 'Elementary School',\n",
    "        r'\\bSHS\\b': 'High School',\n",
    "        r'\\bPRIMARY\\b': 'Elementary School',\n",
    "    }\n",
    "\n",
    "    for pattern, type_name in suffix_map.items():\n",
    "        if re.search(pattern, main_name, flags=re.IGNORECASE):\n",
    "            school_type = type_name\n",
    "            main_name = re.sub(pattern, '', main_name, flags=re.IGNORECASE).strip()\n",
    "            break\n",
    "\n",
    "    main_name = main_name.replace('.', '')\n",
    "\n",
    "    return main_name, extra_info, ps_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0d228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "school = pd.read_csv(\"Lead_Testing_in_Schools.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f709f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Compliance Period', 'School District', 'School', 'County',\n",
       "       'Type of Organization', 'BEDS Code', 'School Website',\n",
       "       'Number of Outlets that Require Sampling',\n",
       "       'Number of Outlets Sampled 2023', 'Number of Outlets Sampled 2024',\n",
       "       'Number of Outlets Sampled 2025', 'Sampling Complete',\n",
       "       'Number of Outlets, Result ≤ 5 ppb',\n",
       "       'Number of Outlets, Result > 5 ppb', 'All Results Received',\n",
       "       'Out of Service or Addressed', 'Remediation Status', 'School Street',\n",
       "       'School City', 'School State', 'School ZIP Code', 'Date Survey Updated',\n",
       "       'County Location', 'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4e5c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Steuben', 'Oneida', 'Chenango', 'Orleans', 'Erie', 'Jefferson',\n",
       "       'Allegany', 'Cattaraugus', 'Suffolk', 'Washington', 'Dutchess',\n",
       "       'Rensselaer', 'Nassau', 'Onondaga', 'Lewis', 'Clinton', 'Albany',\n",
       "       'Westchester', 'Warren', 'Essex', 'St.Lawrence', 'Putnam',\n",
       "       'Monroe', 'Chautauqua', 'Franklin', 'Greene', 'Montgomery',\n",
       "       'Madison', 'Tioga', 'Oswego', 'Delaware', 'Broome', 'Orange',\n",
       "       'Cortland', 'Saratoga', 'Herkimer', 'Tompkins', 'Schenectady',\n",
       "       'Yates', 'Ontario', 'Rockland', 'Otsego', 'Sullivan', 'Wayne',\n",
       "       'Columbia', 'Schoharie', 'Fulton', 'Chemung', 'Hamilton', 'Ulster',\n",
       "       'Wyoming', 'Niagara', 'Queens', 'Richmond', 'Bronx', 'Manhattan',\n",
       "       'Man', 'Kings', 'Schuyler', 'Genesee', 'Seneca', 'Cayuga',\n",
       "       'New York', 'Livingston'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school.County.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a074a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_info = school.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329eedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_info[['Cleaned_school_name','Type','PS_No']] = school_info['School'].apply(lambda x: pd.Series(school_name(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f9d1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_info['Free_lunch']                       = np.nan\n",
    "school_info['Total_students']                   = np.nan\n",
    "school_info['Ratio_free']                       = np.nan\n",
    "school_info['Student_teacher_ratio']            = np.nan\n",
    "school_info['American Indian/Alaska Native']    = np.nan\n",
    "school_info['Asian']                            = np.nan\n",
    "school_info['Black']                            = np.nan\n",
    "school_info['Hispanic']                         = np.nan\n",
    "school_info['White']                            = np.nan\n",
    "school_info['Native Hawaiian/Pacific Islander'] = np.nan\n",
    "school_info['Two or More Races']                = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2300\n",
    "end   = 2399\n",
    "\n",
    "log_filename = f\"schools_data_{start}_{end}_log.txt\"\n",
    "csv_filename = f\"schools_data_{start}_{end}.csv\"\n",
    "\n",
    "log_path = os.path.join(os.getcwd(), log_filename)\n",
    "with open(log_path, \"w\") as log_file, redirect_stdout(log_file):\n",
    "\n",
    "    for idx, row in school_info.iloc[start:end+1].iterrows():\n",
    "        school_name   = row['Cleaned_school_name']\n",
    "        county        = row['County']\n",
    "        school_street = row['School Street']\n",
    "\n",
    "        if county == 'St.Lawrence':\n",
    "            county = 'St. Lawrence'\n",
    "\n",
    "        if county == 'Manhattan':\n",
    "            county = 'New York County'\n",
    "\n",
    "        detail_url = get_school_detail_url(school_name, county, school_street)\n",
    "\n",
    "        if detail_url:\n",
    "            detail_resp = requests.get(detail_url)\n",
    "            if detail_resp.status_code == 200:\n",
    "                lunch      = get_free_reduced_lunch_total(detail_resp.text)\n",
    "                total_kids = get_total_count(detail_resp.text)\n",
    "\n",
    "                try:\n",
    "                    lunch_val = int(lunch.replace(\",\", \"\")) if lunch else np.nan\n",
    "                    total_val = int(total_kids.replace(\",\", \"\")) if total_kids else np.nan\n",
    "                except ValueError:\n",
    "                    lunch_val = np.nan\n",
    "                    total_val = np.nan\n",
    "\n",
    "                school_info.at[idx, 'Free_lunch']     = lunch_val\n",
    "                school_info.at[idx, 'Total_students'] = total_val\n",
    "\n",
    "                if not np.isnan(lunch_val) and not np.isnan(total_val) and total_val != 0:\n",
    "                    school_info.at[idx, 'Ratio_free'] = lunch_val / total_val\n",
    "                \n",
    "                stud_teacher_ratio = get_stud_teacher_ratio(detail_resp.text)\n",
    "                if stud_teacher_ratio:\n",
    "                    try:\n",
    "                        stud_teacher_ratio_float = float(stud_teacher_ratio)\n",
    "                    except(ValueError,TypeError):\n",
    "                        stud_teacher_ratio_float = np.nan\n",
    "                    school_info.at[idx, 'Student_teacher_ratio'] = stud_teacher_ratio_float\n",
    "\n",
    "                demographics = get_demographics(detail_resp.text)\n",
    "                if demographics and not np.isnan(total_val) and total_val!=0:\n",
    "                    for key in demographics:\n",
    "                        if key in school_info.columns:\n",
    "                            ratio = demographics[key]/total_val\n",
    "                            school_info.at[idx, key] = ratio\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to get detail page for {school_name}\")\n",
    "        else:\n",
    "            print(f\"Detail URL not found for {school_name}\")\n",
    "\n",
    "        time.sleep(random.uniform(0.02, 0.04))\n",
    "\n",
    "    if 'Type' in school_info.columns:\n",
    "        school_info = school_info.drop('Type', axis=1)\n",
    "\n",
    "\n",
    "    output_path = os.path.join(os.getcwd(), csv_filename)\n",
    "    school_info.iloc[start:end+1].to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved processed schools to {csv_filename}\")\n",
    "    print(f\"Logs saved to {log_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
